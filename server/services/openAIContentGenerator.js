// OpenAI Content Generator - Generates all assessment content dynamically
// This service sends assessment data to OpenAI and gets back personalized recommendations

const assessmentFramework = require('../data/assessmentFramework');

class OpenAIContentGenerator {
  constructor() {
    this.openai = null;
    this.isInitialized = false;
    
    // Initialize OpenAI if API key is available
    if (process.env.OPENAI_API_KEY) {
      try {
        const OpenAI = require('openai');
        this.openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
        this.isInitialized = true;
        console.log('‚úÖ OpenAI Content Generator initialized');
      } catch (error) {
        console.error('‚ùå Failed to initialize OpenAI:', error.message);
        this.isInitialized = false;
      }
    } else {
      console.warn('‚ö†Ô∏è  OpenAI API key not configured. Content generation will use fallback logic.');
    }
  }

  /**
   * Generate complete assessment results using OpenAI
   * @param {object} assessment - Full assessment object with responses
   * @param {string} pillarId - Optional: specific pillar to generate results for
   * @returns {object} Complete results structure
   */
  async generateAssessmentContent(assessment, pillarId = null) {
    if (!this.isInitialized) {
      console.warn('‚ö†Ô∏è  OpenAI not initialized, using fallback content');
      return this.generateFallbackContent(assessment, pillarId);
    }

    try {
      console.log(`ü§ñ Generating ${pillarId ? 'pillar' : 'overall'} content for assessment ${assessment.id}`);
      
      const prompt = pillarId 
        ? this.buildPillarPrompt(assessment, pillarId)
        : this.buildOverallPrompt(assessment);
      
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4-turbo-preview',
        messages: [
          {
            role: 'system',
            content: this.getSystemPrompt()
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.7,
        max_tokens: 4000,
        response_format: { type: 'json_object' }
      });

      const content = JSON.parse(response.choices[0].message.content);
      console.log('‚úÖ OpenAI content generated successfully');
      
      return pillarId 
        ? this.formatPillarResults(content, assessment, pillarId)
        : this.formatOverallResults(content, assessment);
      
    } catch (error) {
      console.error('‚ùå Error generating content from OpenAI:', error.message);
      return this.generateFallbackContent(assessment, pillarId);
    }
  }

  /**
   * Get system prompt for OpenAI
   */
  getSystemPrompt() {
    return `You are a Databricks platform expert and CTO advisor specializing in data platform maturity assessments.

Your role is to analyze assessment responses and provide:
1. Accurate, data-driven insights based on actual user input
2. Specific, actionable recommendations using latest Databricks features (2024-2025)
3. Strategic guidance focused on business impact and ROI
4. Factual analysis without speculative dollar amounts

Key principles:
- Base ALL recommendations on actual user responses (current state, future state, pain points, comments)
- Reference only real Databricks features with verified capabilities
- Focus on measurable business outcomes, not made-up cost figures
- Provide CTO-level strategic narrative, not just technical lists
- Be specific about WHY recommendations matter to THIS organization

Latest Databricks capabilities to consider:
- Unity Catalog for governance and data sharing
- Delta Live Tables for automated data pipelines
- Lakehouse Monitoring for data quality
- Serverless compute for cost optimization
- AI/BI with Genie for natural language queries
- Mosaic AI for GenAI applications
- Vector Search for RAG applications
- Model Serving for LLM deployment

Return ONLY valid JSON with the exact structure requested.`;
  }

  /**
   * Build prompt for overall assessment results
   */
  buildOverallPrompt(assessment) {
    const { responses } = assessment;
    
    // DEBUG: Log what we're receiving
    console.log('üîç buildOverallPrompt called');
    console.log('üîç Assessment ID:', assessment.id);
    console.log('üîç Responses type:', typeof responses);
    console.log('üîç Responses null/undefined?:', responses === null || responses === undefined);
    console.log('üîç Responses keys:', responses ? Object.keys(responses).length : 0);
    
    // FIX: Ensure responses is an object
    const validResponses = responses || {};
    
    // Extract all filled responses by pillar
    const pillarData = assessmentFramework.assessmentAreas.map(area => {
      const questions = this.getAreaQuestions(area);
      const filledQuestions = [];
      
      questions.forEach(question => {
        const currentState = validResponses[`${question.id}_current_state`];
        const futureState = validResponses[`${question.id}_future_state`];
        const technicalPain = validResponses[`${question.id}_technical_pain`] || [];
        const businessPain = validResponses[`${question.id}_business_pain`] || [];
        const comment = validResponses[`${question.id}_comment`] || '';
        const skipped = validResponses[`${question.id}_skipped`] || false;
        
        if (!skipped && (currentState || futureState)) {
          filledQuestions.push({
            topic: question.topic,
            currentState,
            futureState,
            technicalPain,
            businessPain,
            comment
          });
        }
      });
      
      return {
        pillar: area.name,
        pillarId: area.id,
        questionsAnswered: filledQuestions.length,
        questions: filledQuestions
      };
    });

    return `# Databricks Platform Maturity Assessment Analysis

## Organization Context
- **Organization:** ${assessment.organizationName || 'Not provided'}
- **Industry:** ${assessment.industry || 'Not provided'}
- **Assessment Name:** ${assessment.assessmentName || 'Unnamed Assessment'}

## Assessment Data by Pillar

${pillarData.map(p => `### ${p.pillar} (${p.questionsAnswered} questions answered)

${p.questions.map((q, idx) => `
**Question ${idx + 1}: ${q.topic}**
- Current State: Level ${q.currentState || 'Not answered'}
- Future/Target State: Level ${q.futureState || 'Not answered'}
- Technical Pain Points: ${q.technicalPain.length > 0 ? q.technicalPain.join(', ') : 'None'}
- Business Pain Points: ${q.businessPain.length > 0 ? q.businessPain.join(', ') : 'None'}
- Additional Comments: ${q.comment || 'None'}
`).join('\n')}
`).join('\n\n')}

## Task
Based ONLY on the data provided above, generate a comprehensive overall assessment with:

1. **Overall Maturity Scores:**
   - Current maturity score (average across all answered questions)
   - Target maturity score (average of future states)
   - Maturity gap (target - current)

2. **Pillar-Specific Scores:**
   For each pillar with answered questions, calculate:
   - Current score, Future score, Gap
   
3. **Strategic Executive Summary:**
   Write a CTO-level narrative (300-500 words) covering:
   - Current state assessment with specific strengths/weaknesses identified from responses
   - Critical constraints impacting the organization (be specific based on pain points selected)
   - Transformation roadmap with timeline (reference actual gap sizes)
   - Priority initiatives with specific Databricks features that address identified pain points
   - Expected business outcomes (based on gaps and pain points, not made-up numbers)

4. **Top 5 Priority Recommendations:**
   For each recommendation provide:
   - Title
   - Description (why it matters to THIS organization based on their responses)
   - Specific actions (using latest Databricks features)
   - Business impact (based on pain points addressed)
   - Timeline estimate
   - Priority level (critical/high/medium/low)

Return JSON with this structure:
{
  "overallScores": {
    "currentScore": <number 1-5>,
    "futureScore": <number 1-5>,
    "gap": <number>
  },
  "pillarScores": {
    "<pillarId>": {
      "current": <number 1-5>,
      "future": <number 1-5>,
      "gap": <number>
    }
  },
  "executiveSummary": "<markdown text>",
  "recommendations": [
    {
      "title": "<string>",
      "description": "<string>",
      "actions": ["<action1>", "<action2>"],
      "businessImpact": "<string>",
      "timeline": "<string>",
      "priority": "<critical|high|medium|low>"
    }
  ]
}`;
  }

  /**
   * Build prompt for pillar-specific results
   */
  buildPillarPrompt(assessment, pillarId) {
    const { responses } = assessment;
    const area = assessmentFramework.assessmentAreas.find(a => a.id === pillarId);
    
    if (!area) {
      throw new Error(`Pillar ${pillarId} not found`);
    }
    
    // DEBUG: Log what we're receiving
    console.log('üîç buildPillarPrompt called for pillar:', pillarId);
    console.log('üîç Assessment ID:', assessment.id);
    console.log('üîç Responses null/undefined?:', responses === null || responses === undefined);
    console.log('üîç Responses keys:', responses ? Object.keys(responses).length : 0);
    
    // FIX: Ensure responses is an object
    const validResponses = responses || {};
    
    const questions = this.getAreaQuestions(area);
    const filledQuestions = [];
    
    questions.forEach(question => {
      const currentState = validResponses[`${question.id}_current_state`];
      const futureState = validResponses[`${question.id}_future_state`];
      const technicalPain = validResponses[`${question.id}_technical_pain`] || [];
      const businessPain = validResponses[`${question.id}_business_pain`] || [];
      const comment = validResponses[`${question.id}_comment`] || '';
      const skipped = validResponses[`${question.id}_skipped`] || false;
      
      if (!skipped && (currentState || futureState)) {
        filledQuestions.push({
          topic: question.topic,
          currentState,
          futureState,
          technicalPain,
          businessPain,
          comment
        });
      }
    });

    return `# ${area.name} Pillar Assessment Analysis

## Organization Context
- **Organization:** ${assessment.organizationName || 'Not provided'}
- **Industry:** ${assessment.industry || 'Not provided'}

## ${area.name} Questions (${filledQuestions.length} answered)

${filledQuestions.map((q, idx) => `
**Question ${idx + 1}: ${q.topic}**
- Current State: Level ${q.currentState || 'Not answered'}
- Future/Target State: Level ${q.futureState || 'Not answered'}
- Technical Pain Points: ${q.technicalPain.length > 0 ? q.technicalPain.join(', ') : 'None'}
- Business Pain Points: ${q.businessPain.length > 0 ? q.businessPain.join(', ') : 'None'}
- Additional Comments: ${q.comment || 'None'}
`).join('\n')}

## Task - Act as Databricks ${area.name} SME (Subject Matter Expert)

You are a PASSIONATE Databricks solutions architect with 8+ years of hands-on experience. You've implemented ${area.name} for Fortune 500 companies. You LOVE Databricks and know every feature intimately. You speak with confidence and specificity because you've done this dozens of times.

## Your Databricks Expertise Context (Oct 2024):

**Latest Databricks Capabilities:**
- Unity Catalog: Fine-grained governance, attribute-based access control (ABAC), data lineage across clouds
- Delta Live Tables (DLT): Declarative ETL, auto-scaling, expectations for data quality, CDC support
- Databricks SQL Serverless: Sub-second query response, photon engine, automatic scaling
- MLflow 2.x: Model registry, automated retraining, feature serving, LLM tracking
- Databricks Assistant: AI-powered SQL/Python code generation, debugging assistant
- Vector Search: Native vector database for RAG applications, auto-sync with Delta tables
- Lakehouse Federation: Query Snowflake, BigQuery, PostgreSQL without data movement
- AI/BI Dashboards: Genie for natural language queries, automatic insights
- Workflows: Orchestration with 100+ tasks, dynamic task mapping, better than Airflow
- Databricks Apps: Deploy Streamlit/Gradio apps directly on platform

**Common Anti-Patterns You've Seen:**
- Manual workspace provisioning ‚Üí Use Terraform + Unity Catalog assignment automation
- Scattered notebooks ‚Üí Migrate to DLT pipelines with Git integration
- Manual cluster management ‚Üí Use Serverless SQL and Jobs compute
- Custom monitoring ‚Üí Use System Tables (audit logs, query history, lineage)
- Multiple ETL tools ‚Üí Consolidate to DLT + Workflows
- Fragmented governance ‚Üí Unity Catalog as single source of truth

**Pillar-Specific Databricks Expertise for ${area.name}:**

${this.getPillarSpecificContext(pillarId)}

## Your Task:
Generate DIRECT, ACTIONABLE, UNAMBIGUOUS recommendations based on the data above.

**Remember:** You're not a consultant giving vague advice. You're a hands-on architect who has BUILT this exact solution 50+ times. Give them the EXACT steps you would take if you joined their team tomorrow. Use real feature names, real commands, real timelines from your experience.

### Requirements for Actionable Recommendations:
- **Be Specific**: Name exact Databricks features/products (Unity Catalog, Delta Live Tables, MLflow, etc.)
- **Be Prescriptive**: Tell them WHAT to do, HOW to do it, and WHEN to do it
- **Be Technical**: Include actual implementation steps, not high-level platitudes
- **Address Pain Points**: Explicitly map each recommendation to the pain points they selected
- **Provide Timelines**: Specify sprint/week/month estimates for each phase
- **Include Prerequisites**: State what needs to be in place first

### Bad Example (Too Generic):
‚ùå "Implement proper governance" 
‚ùå "Enhance monitoring and observability"
‚ùå "Improve security posture"

### Good Example (Specific & Actionable):
‚úÖ "Enable Unity Catalog on your workspace within 2 weeks: 1) Create metastore in your region, 2) Assign to workspace, 3) Migrate 5 critical schemas using UC migration tool, 4) Configure external locations for your S3 buckets. This addresses your 'Inconsistent access control' pain point."

‚úÖ "Implement Delta Live Tables for your ETL pipelines: Week 1-2: Identify 3 critical batch jobs, Week 3-4: Rewrite using DLT declarative syntax, Week 5: Set up expectations for data quality, Week 6: Enable CDC for incremental loads. This solves your 'Manual pipeline monitoring' pain."

Generate:

1. **Pillar Maturity Scores:**
   - Current maturity score (average across answered questions)
   - Target maturity score
   - Maturity gap

2. **Executive Summary (100-150 words):**
   - What's working: 2-3 specific strengths from their responses
   - Critical gaps: 2-3 specific weaknesses with business impact
   - Transformation approach: The exact path forward with timeline

3. **Top 3-5 Actionable Recommendations:**
   Each must include:
   - **Title**: Action-oriented (starts with verb: "Enable...", "Migrate...", "Implement...")
   - **Why Now**: Which specific pain point(s) this addresses from their responses
   - **Specific Actions**: Numbered steps (1, 2, 3...) with exact Databricks features
   - **Prerequisites**: What must be in place first
   - **Timeline**: Weeks or sprints (be realistic: 1-4 weeks typical)
   - **Team Required**: Who needs to execute (Data Engineers, Platform Admin, etc.)
   - **Success Metrics**: How to measure completion
   - **Priority**: Critical/High/Medium based on pain severity

4. **Databricks Features/Products** (3-5 specific items):
   - Feature name (e.g., "Unity Catalog", "Delta Live Tables", "Databricks SQL Serverless")
   - Status (GA/Public Preview/Private Preview as of Oct 2024)
   - Why relevant: Map directly to their pain points
   - Quick win or foundational: Flag if this unlocks other capabilities

Return JSON with this structure:
{
  "scores": {
    "current": <number 1-5>,
    "future": <number 1-5>,
    "gap": <number>
  },
  "summary": "<markdown text 100-150 words>",
  "recommendations": [
    {
      "title": "<Action-oriented title starting with verb>",
      "whyNow": "<Which pain points this addresses>",
      "actions": [
        "Step 1: <Specific action with Databricks feature>",
        "Step 2: <Next specific action>",
        "Step 3: <Continue...>"
      ],
      "prerequisites": "<What must be in place first>",
      "timeline": "<Specific weeks/sprints: e.g., '3-4 weeks' or 'Sprint 1-2'>",
      "teamRequired": "<Who executes: Data Engineers, Platform Admin, etc.>",
      "successMetrics": "<How to measure completion>",
      "priority": "<critical|high|medium based on pain severity>"
    }
  ],
  "databricksFeatures": [
    {
      "name": "<Exact Databricks feature name>",
      "status": "<GA|Public Preview|Private Preview>",
      "relevance": "<Why relevant to their pain points>",
      "type": "<quick-win|foundational>",
      "action": "<How to get started with this feature>"
    }
  ]
}`;
  }

  /**
   * Generate pillar-specific prioritized actions from pillar scores
   */
  generatePillarPrioritizedActions(pillarScores, assessment) {
    const actions = [];
    const responses = assessment.responses || {};
    
    Object.keys(pillarScores).forEach(pillarId => {
      const pillar = assessmentFramework.assessmentAreas.find(a => a.id === pillarId);
      if (!pillar) return;
      
      // CRITICAL FIX: Only generate actions for pillars with actual responses
      const pillarHasResponses = pillar.dimensions.some(dimension =>
        dimension.questions.some(question => {
          const currentKey = `${question.id}_current_state`;
          const futureKey = `${question.id}_future_state`;
          return responses[currentKey] !== undefined || responses[futureKey] !== undefined;
        })
      );
      
      if (!pillarHasResponses) {
        console.log(`‚è≠Ô∏è Skipping pillar ${pillarId} - no responses found`);
        return; // Skip this pillar - no data to generate actions from
      }
      
      const scores = pillarScores[pillarId];
      const currentScore = Math.round(scores.current);
      const futureScore = Math.round(scores.future);
      const gap = Math.round(scores.gap);
      
      // Get pain points for this pillar
      const pillarPainPoints = [];
      pillar.dimensions.forEach(dimension => {
        dimension.questions.forEach(question => {
          const techPainKey = `${question.id}_technical_pain`;
          const bizPainKey = `${question.id}_business_pain`;
          
          if (responses[techPainKey]) {
            const painArray = Array.isArray(responses[techPainKey]) ? responses[techPainKey] : [responses[techPainKey]];
            pillarPainPoints.push(...painArray.map(p => `Technical: ${p}`));
          }
          if (responses[bizPainKey]) {
            const painArray = Array.isArray(responses[bizPainKey]) ? responses[bizPainKey] : [responses[bizPainKey]];
            pillarPainPoints.push(...painArray.map(p => `Business: ${p}`));
          }
        });
      });
      
      // Generate action for ALL completed pillars (even if gap is 0)
      actions.push({
        pillarId: pillarId,
        pillarName: pillar.name,
        currentScore: currentScore,
        targetScore: futureScore,
        gap: gap,
        priority: gap >= 2 ? 'critical' : gap >= 1 ? 'high' : 'low',
        rationale: gap > 0 
          ? `This pillar shows a ${gap}-level maturity gap between your current state (Level ${currentScore}) and desired future state (Level ${futureScore}). ${pillarPainPoints.length > 0 ? `You've identified ${pillarPainPoints.length} pain points that need attention.` : 'Focused improvement is needed.'}`
          : `You're satisfied with the current maturity level (Level ${currentScore}) for this pillar. ${pillarPainPoints.length > 0 ? `However, you've identified ${pillarPainPoints.length} pain points that could be addressed to optimize operations.` : 'Continue maintaining best practices.'}`,
        theGood: gap > 0 ? [
          `Clear assessment of current capabilities at Level ${currentScore}`,
          `Defined target state at Level ${futureScore}`,
          `Identified improvement path with structured maturity framework`
        ] : [
          `Achieved target maturity level (Level ${currentScore})`,
          `Current state meets business requirements`,
          `Established foundation for maintaining best practices`
        ],
        theBad: pillarPainPoints.length > 0 ? pillarPainPoints.slice(0, 5) : (gap > 0 ? [
          `${gap}-level maturity gap requiring focused effort`,
          `Need to progress through ${gap} maturity level${gap > 1 ? 's' : ''}`
        ] : [
          'Continue monitoring for new challenges',
          'Stay updated with latest Databricks capabilities'
        ]),
        actions: gap > 0 ? [
          `Progress from Level ${currentScore} (${this.getMaturityLevel(currentScore)?.level || 'Current'}) to Level ${futureScore} (${this.getMaturityLevel(futureScore)?.level || 'Target'})`,
          `Address identified pain points in ${pillar.name}`,
          `Implement structured improvements across all dimensions`,
          `Measure progress against maturity framework`
        ] : [
          `Maintain current Level ${currentScore} (${this.getMaturityLevel(currentScore)?.level || 'Current'}) capabilities`,
          pillarPainPoints.length > 0 ? `Address identified pain points to optimize operations` : 'Continue monitoring and applying best practices',
          `Stay current with latest Databricks features and updates`,
          `Share learnings with other teams`
        ]
      });
    });
    
    // Sort by gap (largest first) then by priority
    return actions.sort((a, b) => {
      if (b.gap !== a.gap) return b.gap - a.gap;
      const priorityOrder = { 'critical': 3, 'high': 2, 'medium': 1 };
      return priorityOrder[b.priority] - priorityOrder[a.priority];
    });
  }

  /**
   * Format overall results from OpenAI response
   */
  formatOverallResults(content, assessment) {
    const { overallScores, pillarScores, executiveSummary, recommendations } = content;
    
    // Generate pillar-specific prioritized actions
    const pillarActions = this.generatePillarPrioritizedActions(pillarScores, assessment);
    
    return {
      overall: {
        currentScore: Math.round(overallScores.currentScore),
        futureScore: Math.round(overallScores.futureScore),
        gap: Math.round(overallScores.gap),
        level: this.getMaturityLevel(overallScores.currentScore),
        summary: executiveSummary
      },
      areaScores: Object.keys(pillarScores).reduce((acc, pillarId) => {
        acc[pillarId] = {
          current: Math.round(pillarScores[pillarId].current),
          future: Math.round(pillarScores[pillarId].future),
          gap: Math.round(pillarScores[pillarId].gap),
          overall: Math.round((pillarScores[pillarId].current + pillarScores[pillarId].future) / 2)
        };
        return acc;
      }, {}),
      categories: this.formatPillarCategories(pillarScores),
      prioritizedActions: pillarActions, // Use pillar-structured actions
      painPointRecommendations: recommendations || [],
      gapBasedActions: [],
      commentBasedInsights: [],
      roadmap: {},
      quickWins: [],
      riskAreas: []
    };
  }

  /**
   * Generate dimension-level gap-based actions for a pillar
   */
  generatePillarGapActions(assessment, pillarId) {
    const area = assessmentFramework.assessmentAreas.find(a => a.id === pillarId);
    if (!area) return [];

    const responses = assessment.responses || {};
    const actions = [];

    area.dimensions.forEach(dimension => {
      dimension.questions.forEach(question => {
        const currentKey = `${question.id}_current_state`;
        const futureKey = `${question.id}_future_state`;
        
        const currentValue = parseInt(responses[currentKey]) || 0;
        const futureValue = parseInt(responses[futureKey]) || 0;
        const gap = futureValue - currentValue;

        if (gap > 0) {
          // Get the maturity level labels
          const currentLevel = this.getMaturityLevel(currentValue);
          const futureLevel = this.getMaturityLevel(futureValue);
          
          actions.push({
            dimension: dimension.name,
            question: question.question,
            current: currentValue,
            future: futureValue,
            gap: parseFloat(gap.toFixed(1)), // Fix floating point precision
            currentLevel: currentLevel ? currentLevel.level : 'Unknown',
            futureLevel: futureLevel ? futureLevel.level : 'Unknown',
            recommendation: `Progress from Level ${currentValue} (${currentLevel?.level || 'Unknown'}) to Level ${futureValue} (${futureLevel?.level || 'Unknown'}) by implementing structured improvements in ${dimension.name.toLowerCase()}.`
          });
        }
      });
    });

    // Sort by gap (largest first)
    return actions.sort((a, b) => b.gap - a.gap);
  }

  /**
   * Format pillar results from OpenAI response
   */
  formatPillarResults(content, assessment, pillarId) {
    const { scores, summary, recommendations, databricksFeatures } = content;
    const area = assessmentFramework.assessmentAreas.find(a => a.id === pillarId);
    
    // Generate dimension-level gap actions
    const gapActions = this.generatePillarGapActions(assessment, pillarId);
    
    return {
      pillar: {
        id: pillarId,
        name: area.name,
        currentScore: Math.round(scores.current),
        futureScore: Math.round(scores.future),
        gap: parseFloat(scores.gap.toFixed(1)), // Fix floating point precision
        level: this.getMaturityLevel(scores.current),
        targetLevel: this.getMaturityLevel(scores.future)
      },
      summary: summary || '',
      recommendations: recommendations || [],
      databricksFeatures: databricksFeatures || [],
      painPointRecommendations: recommendations || [],
      gapBasedActions: gapActions,
      commentBasedInsights: []
    };
  }

  /**
   * Format pillar categories for overall results
   */
  formatPillarCategories(pillarScores) {
    const categories = {};
    
    Object.keys(pillarScores).forEach(pillarId => {
      const area = assessmentFramework.assessmentAreas.find(a => a.id === pillarId);
      const scores = pillarScores[pillarId];
      
      categories[pillarId] = {
        name: area.name,
        currentScore: Math.round(scores.current),
        futureScore: Math.round(scores.future),
        gap: Math.round(scores.gap),
        level: this.getMaturityLevel(scores.current),
        targetLevel: this.getMaturityLevel(scores.future),
        recommendations: []
      };
    });
    
    return categories;
  }

  /**
   * Fallback content when OpenAI is unavailable
   */
  generateFallbackContent(assessment, pillarId) {
    console.log('‚ö†Ô∏è  Generating fallback content (OpenAI unavailable)');
    console.log('üîç Fallback - Assessment ID:', assessment.id);
    console.log('üîç Fallback - Responses null/undefined?:', assessment.responses === null || assessment.responses === undefined);
    console.log('üîç Fallback - Responses keys:', assessment.responses ? Object.keys(assessment.responses).length : 0);
    
    // FIX: Ensure responses is not null
    const validResponses = assessment.responses || {};
    
    // Import the adaptive engine for fallback
    const AdaptiveRecommendationEngine = require('./adaptiveRecommendationEngine');
    const engine = new AdaptiveRecommendationEngine();
    
    if (pillarId) {
      // Generate pillar-specific fallback
      const recommendations = engine.generateAdaptiveRecommendations(
        validResponses,
        [pillarId]
      );
      
      const area = assessmentFramework.assessmentAreas.find(a => a.id === pillarId);
      const scores = recommendations.areaScores[pillarId] || { current: 0, future: 0, gap: 0 };
      
      // Generate dimension-level gap actions using the same method as OpenAI path
      const gapActions = this.generatePillarGapActions(assessment, pillarId);
      
      return {
        pillar: {
          id: pillarId,
          name: area.name,
          currentScore: scores.current,
          futureScore: scores.future,
          gap: parseFloat(scores.gap.toFixed(1)), // Fix floating point precision
          level: this.getMaturityLevel(scores.current),
          targetLevel: this.getMaturityLevel(scores.future)
        },
        summary: `Based on your responses, this pillar shows a ${scores.gap}-level gap requiring focused attention.`,
        recommendations: recommendations.prioritizedActions || [],
        databricksFeatures: [],
        painPointRecommendations: recommendations.painPointRecommendations || [],
        gapBasedActions: gapActions, // Use dimension-level gaps
        commentBasedInsights: recommendations.commentBasedInsights || []
      };
    } else {
      // Generate overall fallback
      const recommendations = engine.generateAdaptiveRecommendations(
        validResponses
      );
      
      // Transform to use pillar-structured actions
      const pillarActions = this.generatePillarPrioritizedActions(recommendations.areaScores, assessment);
      recommendations.prioritizedActions = pillarActions;
      
      return recommendations;
    }
  }

  /**
   * Get pillar-specific Databricks expertise context
   */
  getPillarSpecificContext(pillarId) {
    const contexts = {
      platform_governance: `
**Platform & Governance Expertise:**
- Unity Catalog is THE game-changer (GA since 2023). It's not optional anymore.
- Start with account-level metastore ‚Üí Assign to workspaces ‚Üí Migrate legacy Hive metastore
- Use external locations for S3/ADLS/GCS buckets (no more mount points!)
- Implement attribute-based access control (ABAC) for dynamic row/column filtering
- System tables (system.access, system.audit, system.query) are goldmines for monitoring
- Terraform provider 1.x has full UC support - infrastructure as code is mandatory
- Personal Compute clusters for dev, Serverless for production (cost optimization)
- Compliance view shows PII/PHI automatically - huge for GDPR/HIPAA

**Quick Wins (Week 1-2):**
1. Enable UC on workspace
2. Create 3-tier namespace (catalog.schema.table)
3. Set up external locations
4. Migrate 5 critical tables`,

      data_engineering: `
**Data Engineering Expertise:**
- Delta Live Tables (DLT) > custom notebooks. Period. 10x faster to build, 5x less code.
- Use DLT expectations for data quality: @dlt.expect() for warnings, @dlt.expect_or_drop() for drops
- Streaming tables with Auto Loader for S3/ADLS (handles schema evolution automatically)
- Liquid clustering replaces Z-ORDER (no more manual optimization!)
- Change Data Feed (CDF) for incremental processing - enable with ALTER TABLE
- Unity Catalog volumes for unstructured data (PDFs, images, etc.)
- Workflows > Airflow - native integration, better UI, automatic retries

**Quick Wins (Week 1-2):**
1. Convert 1 notebook to DLT pipeline
2. Enable Auto Loader for landing zone
3. Add expectations for data quality
4. Set up incremental processing with CDF`,

      analytics_bi: `
**Analytics & BI Expertise:**
- Databricks SQL Serverless = game over for Snowflake on cost (pay per query second)
- Photon engine 2.0: 3-5x faster, no config needed
- Genie (AI/BI) for natural language queries - business users LOVE this
- SQL warehouses with serverless compute auto-scale 0 to 100+ clusters
- Query federation to read Snowflake/BigQuery without ETL (saves months)
- Dashboards with automatic refresh, alerts, scheduled emails
- SQL UDFs and Databricks Functions for reusable logic
- Query profile shows exact bottlenecks (scan vs compute vs network)

**Quick Wins (Week 1-2):**
1. Create serverless SQL warehouse
2. Connect Power BI/Tableau
3. Build 5 dashboards from key tables
4. Enable Genie for business users`,

      machine_learning: `
**Machine Learning Expertise:**
- MLflow is industry standard (not just Databricks) - 10M+ downloads/month
- Feature Store for reusable features across models (training/serving consistency)
- Model serving with auto-scaling (CPU or GPU), A/B testing built-in
- AutoML for baseline models in 10 minutes (95% accuracy often)
- Hyperopt for distributed hyperparameter tuning (100x faster)
- Unity Catalog for model governance (lineage from data to model to endpoint)
- Mosaic AI Model Training for distributed LLMs (LLaMA, Mistral, etc.)

**Quick Wins (Week 1-2):**
1. Register existing model in MLflow
2. Deploy to Model Serving endpoint
3. Create Feature Store for top 10 features
4. Run AutoML on one use case`,

      generative_ai: `
**Generative AI Expertise:**
- Mosaic AI is the ONLY platform that does end-to-end LLMs (training ‚Üí serving ‚Üí monitoring)
- Vector Search (GA): Native integration with Delta tables, auto-sync, 10x faster than Pinecone
- RAG Studio for building retrieval apps visually (no code needed for PoC)
- DBRX model (open-source, outperforms GPT-3.5) runs natively
- LLM eval suite for testing quality (perplexity, ROUGE, BLEU)
- AI Functions (ai_query, ai_extract) in SQL - query your data with natural language
- Model Serving supports vLLM, TGI, MLflow (flexible deployment)
- Pay per token pricing for Foundation Model APIs

**Quick Wins (Week 1-2):**
1. Create vector search endpoint
2. Ingest documents to Delta table
3. Build RAG chatbot with RAG Studio
4. Deploy with Databricks Apps`,

      operational_excellence: `
**Operational Excellence Expertise:**
- System tables are your monitoring layer (free, always on, 14 days retention)
- Use system.compute.clusters to track cluster utilization and right-size
- Query history (system.query.history) shows slow queries and optimization opportunities
- Workflows for orchestration: 100+ task types, dynamic mapping, error handling
- Databricks CLI 0.2+ uses REST API 2.1 (10x faster than legacy CLI)
- Terraform provider 1.x for infrastructure as code (workspaces, clusters, jobs, notebooks)
- Budget alerts to prevent cost overruns (set at workspace or job level)
- Enhanced autoscaling: Scale down to zero for cost, scale up in seconds

**Quick Wins (Week 1-2):**
1. Query system.compute.clusters for right-sizing
2. Create Terraform for common patterns
3. Set up budget alerts
4. Migrate 3 jobs to Workflows`
    };

    return contexts[pillarId] || `**${pillarId} - Expertise coming soon**`;
  }

  /**
   * Get area questions
   */
  getAreaQuestions(area) {
    const questions = [];
    if (area.dimensions) {
      area.dimensions.forEach(dimension => {
        if (dimension.questions) {
          questions.push(...dimension.questions);
        }
      });
    } else if (area.questions) {
      questions.push(...area.questions);
    }
    return questions;
  }

  /**
   * Get maturity level for a given score
   */
  getMaturityLevel(score) {
    const roundedScore = Math.round(score);
    const level = Math.max(1, Math.min(5, roundedScore));
    
    const maturityLevels = {
      1: {
        level: 'Initial',
        description: 'Ad-hoc processes, limited capabilities',
        color: '#ff4444'
      },
      2: {
        level: 'Developing',
        description: 'Basic implementation with some structure',
        color: '#ff8800'
      },
      3: {
        level: 'Defined',
        description: 'Structured approach with established processes',
        color: '#ffaa00'
      },
      4: {
        level: 'Managed',
        description: 'Advanced capabilities with strong governance',
        color: '#88cc00'
      },
      5: {
        level: 'Optimized',
        description: 'Industry-leading, AI-driven optimization',
        color: '#00cc44'
      }
    };
    
    return maturityLevels[level];
  }
}

module.exports = OpenAIContentGenerator;

